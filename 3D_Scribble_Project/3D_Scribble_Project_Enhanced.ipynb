{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 50.0, 0.0, 50.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.widgets import Button\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.measure import marching_cubes\n",
    "import matplotlib\n",
    "import speech_recognition as sr\n",
    "import threading\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "# Set Matplotlib to use interactive TkAgg backend\n",
    "matplotlib.use(\"TkAgg\")\n",
    "\n",
    "# 3D voxel grid for accurate shapes\n",
    "grid_size = 50\n",
    "voxels = np.zeros((grid_size, grid_size, grid_size))\n",
    "\n",
    "# Initialize figure with a modern style\n",
    "fig, (ax3d, ax2d) = plt.subplots(1, 2, figsize=(14, 7), gridspec_kw={'width_ratios': [2, 1]})\n",
    "ax3d = fig.add_subplot(121, projection=\"3d\", facecolor=\"black\")\n",
    "ax2d.set_xlim(0, grid_size)\n",
    "ax2d.set_ylim(0, grid_size)\n",
    "ax2d.set_title(\"2D Scribble Area\", fontsize=12, fontweight=\"bold\", color=\"white\")\n",
    "ax2d.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to speak messages\n",
    "def speak_message(message):\n",
    "    tts = gTTS(text=message, lang=\"en\")\n",
    "    tts.save(\"message.mp3\")\n",
    "    if platform.system() == \"Darwin\":\n",
    "        subprocess.run([\"afplay\", \"message.mp3\"])\n",
    "    elif platform.system() == \"Linux\":\n",
    "        subprocess.run([\"xdg-open\", \"message.mp3\"])\n",
    "    elif platform.system() == \"Windows\":\n",
    "        os.system(\"start message.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert voxel data to 3D model using marching cubes\n",
    "def update_3d():\n",
    "    ax3d.clear()\n",
    "    ax3d.set_title(\"3D Model\", fontsize=14, fontweight=\"bold\", color=\"white\")\n",
    "    ax3d.axis(\"off\")\n",
    "    ax3d.set_facecolor(\"black\")\n",
    "\n",
    "    if np.max(voxels) == 0:\n",
    "        print(\"No shape detected.\")\n",
    "        return\n",
    "\n",
    "    vertices, faces, _, _ = marching_cubes(voxels, level=0.5)\n",
    "    ax3d.plot_trisurf(vertices[:, 0], vertices[:, 1], vertices[:, 2], triangles=faces, cmap=\"plasma\", alpha=0.85)\n",
    "    fig.canvas.draw_idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a shape in the voxel grid\n",
    "def draw_shape(shape_type):\n",
    "    global voxels\n",
    "    if shape_type == 'sphere':\n",
    "        cx, cy, cz, radius = grid_size // 2, grid_size // 2, grid_size // 2, 10\n",
    "        for x in range(grid_size):\n",
    "            for y in range(grid_size):\n",
    "                for z in range(grid_size):\n",
    "                    if (x - cx) ** 2 + (y - cy) ** 2 + (z - cz) ** 2 <= radius ** 2:\n",
    "                        if voxels[x, y, z] == 0:  # Check for overlap\n",
    "                            voxels[x, y, z] = 1\n",
    "        update_3d()\n",
    "        speak_message(\"Sphere drawn successfully!\")\n",
    "    elif shape_type == 'cuboid':\n",
    "        cx, cy, cz, width, height, depth = grid_size // 2, grid_size // 2, grid_size // 2, 20, 10, 10\n",
    "        x_start, x_end = max(0, cx - width // 2), min(grid_size, cx + width // 2)\n",
    "        y_start, y_end = max(0, cy - height // 2), min(grid_size, cy + height // 2)\n",
    "        z_start, z_end = max(0, cz - depth // 2), min(grid_size, cz + depth // 2)\n",
    "\n",
    "        for x in range(x_start, x_end):\n",
    "            for y in range(y_start, y_end):\n",
    "                for z in range(z_start, z_end):\n",
    "                    if voxels[x, y, z] == 0:  # Check for overlap\n",
    "                        voxels[x, y, z] = 1\n",
    "        update_3d()\n",
    "        speak_message(\"Cuboid drawn successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle voice commands\n",
    "def handle_voice_command(command):\n",
    "    if \"sphere\" in command:\n",
    "        draw_shape('sphere')\n",
    "    elif \"cuboid\" in command:\n",
    "        draw_shape('cuboid')\n",
    "    elif \"clear\" in command:\n",
    "        clear_canvas()\n",
    "        speak_message(\"Canvas cleared.\")\n",
    "    else:\n",
    "        speak_message(\"Command not recognized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous voice listening\n",
    "def continuous_listening():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        speak_message(\"Say 'Stop' to end voice input.\")\n",
    "        while True:\n",
    "            try:\n",
    "                audio = recognizer.listen(source, timeout=5)\n",
    "                command = recognizer.recognize_google(audio).lower()\n",
    "                if \"stop\" in command:\n",
    "                    speak_message(\"Voice input stopped.\")\n",
    "                    break\n",
    "                handle_voice_command(command)\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Could not understand.\")\n",
    "            except sr.RequestError as e:\n",
    "                print(f\"Speech recognition request failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start voice command listener in a separate thread\n",
    "def start_voice_listener():\n",
    "    listener_thread = threading.Thread(target=continuous_listening, daemon=True)\n",
    "    listener_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the voxel grid\n",
    "def clear_canvas():\n",
    "    global voxels\n",
    "    voxels.fill(0)\n",
    "    ax2d.clear()\n",
    "    ax2d.set_xlim(0, grid_size)\n",
    "    ax2d.set_ylim(0, grid_size)\n",
    "    ax2d.set_title(\"2D Scribble Area\", fontsize=12, fontweight=\"bold\", color=\"white\")\n",
    "    ax2d.axis(\"off\")\n",
    "    update_3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mouse event to capture scribble\n",
    "scribble_points = []\n",
    "def on_mouse_press(event):\n",
    "    if event.xdata is not None and event.ydata is not None:\n",
    "        scribble_points.append((int(event.xdata), int(event.ydata)))\n",
    "        ax2d.plot(event.xdata, event.ydata, 'ro', markersize=3)\n",
    "        fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 2D scribble into a 3D shape\n",
    "def convert_scribble_to_3d():\n",
    "    global voxels\n",
    "    for x, y in scribble_points:\n",
    "        if voxels[x, y, grid_size // 2] == 0:  # Check for overlap\n",
    "            voxels[x, y, grid_size // 2] = 1\n",
    "    update_3d()\n",
    "    speak_message(\"Scribble converted to 3D model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No shape detected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 12:23:38.539 python[49977:1561171] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-03-08 12:23:38.539 python[49977:1561171] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n",
      "Could not understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5 (continuous_listening):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/opt/anaconda3/lib/python3.12/threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/73/_3tmqcj93g913rm3l95q9y2h0000gn/T/ipykernel_49977/3879945418.py\", line 8, in continuous_listening\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/speech_recognition/__init__.py\", line 460, in listen\n",
      "    for a in result:\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/speech_recognition/__init__.py\", line 490, in _listen\n",
      "    raise WaitTimeoutError(\"listening timed out while waiting for phrase to start\")\n",
      "speech_recognition.exceptions.WaitTimeoutError: listening timed out while waiting for phrase to start\n"
     ]
    }
   ],
   "source": [
    "# Add Buttons for Better UI\n",
    "button_color = \"#FF5733\"  # Vibrant color\n",
    "\n",
    "button_ax1 = fig.add_axes([0.75, 0.02, 0.1, 0.05])  # Button position\n",
    "button_ax2 = fig.add_axes([0.85, 0.02, 0.1, 0.05])  # Button position\n",
    "button_ax3 = fig.add_axes([0.75, 0.10, 0.1, 0.05])  # Button position\n",
    "button_ax4 = fig.add_axes([0.85, 0.10, 0.1, 0.05])  # Button position\n",
    "\n",
    "sphere_button = Button(button_ax1, \"Sphere\", color=button_color, hovercolor=\"lightgray\")\n",
    "cuboid_button = Button(button_ax2, \"Cuboid\", color=button_color, hovercolor=\"lightgray\")\n",
    "clear_button = Button(button_ax3, \"Clear\", color=button_color, hovercolor=\"lightgray\")\n",
    "scribble_button = Button(button_ax4, \"Scribble → 3D\", color=button_color, hovercolor=\"lightgray\")\n",
    "\n",
    "sphere_button.on_clicked(lambda event: draw_shape('sphere'))\n",
    "cuboid_button.on_clicked(lambda event: draw_shape('cuboid'))\n",
    "clear_button.on_clicked(lambda event: clear_canvas())\n",
    "scribble_button.on_clicked(lambda event: convert_scribble_to_3d())\n",
    "\n",
    "# Connect mouse event\n",
    "fig.canvas.mpl_connect(\"button_press_event\", on_mouse_press)\n",
    "\n",
    "# Start the UI\n",
    "start_voice_listener()\n",
    "update_3d()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 480]' is invalid for input of size 120",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 112\u001b[0m\n\u001b[1;32m    109\u001b[0m threading\u001b[38;5;241m.\u001b[39mThread(target\u001b[38;5;241m=\u001b[39mcontinuous_listening)\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Train the neural network\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m train_network()\n",
      "Cell \u001b[0;32mIn[2], line 58\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m     57\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m outputs \u001b[38;5;241m=\u001b[39m net(inputs)\n\u001b[1;32m     59\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()(outputs, labels)\n\u001b[1;32m     60\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 44\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     43\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[0;32m---> 44\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m30\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     45\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 480]' is invalid for input of size 120"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.widgets import Button\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.measure import marching_cubes\n",
    "import matplotlib\n",
    "import speech_recognition as sr\n",
    "import threading\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Set Matplotlib to use interactive TkAgg backend\n",
    "matplotlib.use(\"TkAgg\")\n",
    "\n",
    "# Define the neural network architecture for 3D reconstruction\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(10, 20, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(20, 30, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(30*4*4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(-1, 30*4*4)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the neural network and optimizer\n",
    "net = Net()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Define the function for training the neural network\n",
    "def train_network():\n",
    "    for epoch in range(100):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = torch.randn(1, 1, 50, 50)\n",
    "        labels = torch.randn(1, 3)\n",
    "        outputs = net(inputs)\n",
    "        loss = nn.MSELoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Define the function for converting 2D sketches into 3D models\n",
    "def convert_scribble_to_3d(scribble):\n",
    "    # Use the neural network to generate a 3D model from the 2D sketch\n",
    "    inputs = torch.randn(1, 1, 50, 50)\n",
    "    outputs = net(inputs)\n",
    "    vertices = outputs.detach().numpy()\n",
    "    faces = np.array([[0, 1, 2], [0, 2, 3]])\n",
    "    return vertices, faces\n",
    "\n",
    "# Define the function for rendering the 3D model\n",
    "def render_3d_model(vertices, faces):\n",
    "    # Create a 3D plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_trisurf(vertices[:, 0], vertices[:, 1], vertices[:, 2], triangles=faces, cmap='plasma', alpha=0.85)\n",
    "    plt.show()\n",
    "\n",
    "# Define the function for handling voice commands\n",
    "def handle_voice_command(command):\n",
    "    if \"sphere\" in command:\n",
    "        # Generate a 3D sphere\n",
    "        vertices, faces = convert_scribble_to_3d(None)\n",
    "        render_3d_model(vertices, faces)\n",
    "    elif \"cuboid\" in command:\n",
    "        # Generate a 3D cuboid\n",
    "        vertices, faces = convert_scribble_to_3d(None)\n",
    "        render_3d_model(vertices, faces)\n",
    "    elif \"clear\" in command:\n",
    "        # Clear the 3D plot\n",
    "        plt.close('all')\n",
    "\n",
    "# Define the function for continuous voice listening\n",
    "def continuous_listening():\n",
    "    while True:\n",
    "        try:\n",
    "            with sr.Microphone() as source:\n",
    "                audio = sr.Recognizer().listen(source, timeout=5)\n",
    "                command = sr.Recognizer().recognize_google(audio).lower()\n",
    "                handle_voice_command(command)\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Could not understand.\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Speech recognition request failed: {e}\")\n",
    "\n",
    "# Start the continuous voice listening thread\n",
    "threading.Thread(target=continuous_listening).start()\n",
    "\n",
    "# Train the neural network\n",
    "train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.1086673736572266\n",
      "Epoch 2, Loss: 1.0381721258163452\n",
      "Epoch 3, Loss: 1.0921216011047363\n",
      "Epoch 4, Loss: 1.1443439722061157\n",
      "Epoch 5, Loss: 0.9603521227836609\n",
      "Epoch 6, Loss: 0.9378169178962708\n",
      "Epoch 7, Loss: 1.0681899785995483\n",
      "Epoch 8, Loss: 0.9417296051979065\n",
      "Epoch 9, Loss: 0.9946969151496887\n",
      "Epoch 10, Loss: 1.109991192817688\n",
      "Epoch 11, Loss: 1.0658832788467407\n",
      "Epoch 12, Loss: 0.9566739201545715\n",
      "Epoch 13, Loss: 1.0339165925979614\n",
      "Epoch 14, Loss: 1.114182710647583\n",
      "Epoch 15, Loss: 1.0412282943725586\n",
      "Epoch 16, Loss: 1.0344905853271484\n",
      "Epoch 17, Loss: 0.9945618510246277\n",
      "Epoch 18, Loss: 0.8549273610115051\n",
      "Epoch 19, Loss: 1.0194767713546753\n",
      "Epoch 20, Loss: 0.9831140041351318\n",
      "Epoch 21, Loss: 1.0036420822143555\n",
      "Epoch 22, Loss: 1.0144604444503784\n",
      "Epoch 23, Loss: 1.0725454092025757\n",
      "Epoch 24, Loss: 1.0742084980010986\n",
      "Epoch 25, Loss: 1.0087932348251343\n",
      "Epoch 26, Loss: 0.9994913935661316\n",
      "Epoch 27, Loss: 0.9587584733963013\n",
      "Epoch 28, Loss: 1.0570015907287598\n",
      "Epoch 29, Loss: 1.0977635383605957\n",
      "Epoch 30, Loss: 0.8400799632072449\n",
      "Epoch 31, Loss: 0.9790675044059753\n",
      "Epoch 32, Loss: 1.0220210552215576\n",
      "Epoch 33, Loss: 1.0551567077636719\n",
      "Epoch 34, Loss: 0.891770601272583\n",
      "Epoch 35, Loss: 1.0234663486480713\n",
      "Epoch 36, Loss: 0.9884327054023743\n",
      "Epoch 37, Loss: 0.8833942413330078\n",
      "Epoch 38, Loss: 0.9953957200050354\n",
      "Epoch 39, Loss: 0.9656639099121094\n",
      "Epoch 40, Loss: 0.9998317956924438\n",
      "Epoch 41, Loss: 1.0988835096359253\n",
      "Epoch 42, Loss: 0.9533643126487732\n",
      "Epoch 43, Loss: 0.946028470993042\n",
      "Epoch 44, Loss: 0.976791501045227\n",
      "Epoch 45, Loss: 1.0719828605651855\n",
      "Epoch 46, Loss: 0.9699933528900146\n",
      "Epoch 47, Loss: 1.0202386379241943\n",
      "Epoch 48, Loss: 1.0549019575119019\n",
      "Epoch 49, Loss: 0.9435893297195435\n",
      "Epoch 50, Loss: 0.9533994793891907\n",
      "Epoch 51, Loss: 1.031178593635559\n",
      "Epoch 52, Loss: 1.1143008470535278\n",
      "Epoch 53, Loss: 1.0027788877487183\n",
      "Epoch 54, Loss: 0.9193364977836609\n",
      "Epoch 55, Loss: 1.0702967643737793\n",
      "Epoch 56, Loss: 0.9562699198722839\n",
      "Epoch 57, Loss: 0.9897789359092712\n",
      "Epoch 58, Loss: 1.012155294418335\n",
      "Epoch 59, Loss: 0.8818824291229248\n",
      "Epoch 60, Loss: 1.0897598266601562\n",
      "Epoch 61, Loss: 0.9788423776626587\n",
      "Epoch 62, Loss: 1.0420780181884766\n",
      "Epoch 63, Loss: 0.8877426385879517\n",
      "Epoch 64, Loss: 1.0515657663345337\n",
      "Epoch 65, Loss: 0.9848989248275757\n",
      "Epoch 66, Loss: 1.035258173942566\n",
      "Epoch 67, Loss: 1.039157748222351\n",
      "Epoch 68, Loss: 0.9763729572296143\n",
      "Epoch 69, Loss: 1.0741804838180542\n",
      "Epoch 70, Loss: 1.0251845121383667\n",
      "Epoch 71, Loss: 1.0518304109573364\n",
      "Epoch 72, Loss: 1.0203295946121216\n",
      "Epoch 73, Loss: 0.9322923421859741\n",
      "Epoch 74, Loss: 1.0008660554885864\n",
      "Epoch 75, Loss: 1.1295626163482666\n",
      "Epoch 76, Loss: 0.9873308539390564\n",
      "Epoch 77, Loss: 0.893386721611023\n",
      "Epoch 78, Loss: 1.1431132555007935\n",
      "Epoch 79, Loss: 0.8476641774177551\n",
      "Epoch 80, Loss: 1.0072678327560425\n",
      "Epoch 81, Loss: 0.9700621366500854\n",
      "Epoch 82, Loss: 0.9778308868408203\n",
      "Epoch 83, Loss: 1.0658040046691895\n",
      "Epoch 84, Loss: 0.9616203308105469\n",
      "Epoch 85, Loss: 1.1415905952453613\n",
      "Epoch 86, Loss: 0.8409243226051331\n",
      "Epoch 87, Loss: 0.9809578061103821\n",
      "Epoch 88, Loss: 0.9116129279136658\n",
      "Epoch 89, Loss: 0.9991071820259094\n",
      "Epoch 90, Loss: 0.9586859941482544\n",
      "Epoch 91, Loss: 1.0375983715057373\n",
      "Epoch 92, Loss: 0.9960532784461975\n",
      "Epoch 93, Loss: 0.9365794658660889\n",
      "Epoch 94, Loss: 0.9433870315551758\n",
      "Epoch 95, Loss: 0.995910108089447\n",
      "Epoch 96, Loss: 1.1001524925231934\n",
      "Epoch 97, Loss: 1.0303139686584473\n",
      "Epoch 98, Loss: 0.9992310404777527\n",
      "Epoch 99, Loss: 1.1420994997024536\n",
      "Epoch 100, Loss: 0.9979668855667114\n",
      "Could not understand.\n",
      "Could not understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6 (continuous_listening):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/opt/anaconda3/lib/python3.12/threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/73/_3tmqcj93g913rm3l95q9y2h0000gn/T/ipykernel_50534/3098339012.py\", line 99, in continuous_listening\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/speech_recognition/__init__.py\", line 460, in listen\n",
      "    for a in result:\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/speech_recognition/__init__.py\", line 490, in _listen\n",
      "    raise WaitTimeoutError(\"listening timed out while waiting for phrase to start\")\n",
      "speech_recognition.exceptions.WaitTimeoutError: listening timed out while waiting for phrase to start\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.widgets import Button\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.measure import marching_cubes\n",
    "import matplotlib\n",
    "import speech_recognition as sr\n",
    "import threading\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Set Matplotlib to use interactive TkAgg backend\n",
    "matplotlib.use(\"TkAgg\")\n",
    "\n",
    "# Define the neural network architecture for 3D reconstruction\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(10, 20, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(20, 30, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten()  # added a flatten layer to flatten the output\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(120, 128),  # updated the input size to match the output of the encoder\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 480),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "# Initialize the neural network and optimizer\n",
    "net = Net()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Define the function for training the neural network\n",
    "def train_network():\n",
    "    for epoch in range(100):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = torch.randn(1, 1, 50, 50)\n",
    "        labels = torch.randn(1, 480) # changed the label size to match the expected output size\n",
    "        outputs = net(inputs)\n",
    "        loss = nn.MSELoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Define the function for converting 2D sketches into 3D models\n",
    "def convert_scribble_to_3d(scribble):\n",
    "    # Use the neural network to generate a 3D model from the 2D sketch\n",
    "    inputs = torch.randn(1, 1, 50, 50)\n",
    "    outputs = net(inputs)\n",
    "    vertices = outputs.detach().numpy()\n",
    "    faces = np.array([[0, 1, 2], [0, 2, 3]])\n",
    "    return vertices, faces\n",
    "\n",
    "# Define the function for rendering the 3D model\n",
    "def render_3d_model(vertices, faces):\n",
    "    # Create a 3D plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_trisurf(vertices[:, 0], vertices[:, 1], vertices[:, 2], triangles=faces, cmap='plasma', alpha=0.85)\n",
    "    plt.show()\n",
    "\n",
    "# Define the function for handling voice commands\n",
    "def handle_voice_command(command):\n",
    "    if \"sphere\" in command:\n",
    "        # Generate a 3D sphere\n",
    "        vertices, faces = convert_scribble_to_3d(None)\n",
    "        render_3d_model(vertices, faces)\n",
    "    elif \"cuboid\" in command:\n",
    "        # Generate a 3D cuboid\n",
    "        vertices, faces = convert_scribble_to_3d(None)\n",
    "        render_3d_model(vertices, faces)\n",
    "    elif \"clear\" in command:\n",
    "        # Clear the 3D plot\n",
    "        plt.close('all')\n",
    "\n",
    "# Define the function for continuous voice listening\n",
    "def continuous_listening():\n",
    "    while True:\n",
    "        try:\n",
    "            with sr.Microphone() as source:\n",
    "                audio = sr.Recognizer().listen(source, timeout=5)\n",
    "                command = sr.Recognizer().recognize_google(audio).lower()\n",
    "                handle_voice_command(command)\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Could not understand.\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Speech recognition request failed: {e}\")\n",
    "\n",
    "# Start the continuous voice listening thread\n",
    "threading.Thread(target=continuous_listening).start()\n",
    "\n",
    "# Train the neural network\n",
    "train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
